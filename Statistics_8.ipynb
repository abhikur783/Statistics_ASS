{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\n",
    "Ans:\n",
    "    Assumptions of ANOVA:\n",
    "1. Independence: Observations are independent of each other.\n",
    "2. Normality: The residuals (the differences between observed and predicted values) are normally distributed.\n",
    "3. Homogeneity of variance: The variability of the residuals is approximately equal across groups.\n",
    "4. Random sampling: Data is collected through random sampling from the population.\n",
    "\n",
    "Examples of violations:\n",
    "1. Non-independence: Observations within groups are correlated, such as in clustered data or repeated measures designs.\n",
    "2. Non-normality: Residuals are not normally distributed, often occurring in skewed or heavily tailed distributions.\n",
    "3. Heterogeneity of variance: The variability of residuals differs significantly between groups, violating the assumption of\n",
    "    equal variances.\n",
    "4. Non-random sampling: Data is collected through non-random sampling methods, leading to biased results.\n",
    "\n",
    "Violation of these assumptions can lead to inaccurate or invalid results from ANOVA analysis, making the interpretations less \n",
    "reliable. It is essential to check for these assumptions and consider alternative analysis methods if violations are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "Ans:\n",
    "    The three types of ANOVA are:\n",
    "\n",
    "1. One-way ANOVA: Used when comparing the means of three or more groups that are independent of each other. It assesses whether \n",
    "    there are significant differences between the group means.\n",
    "\n",
    "2. Two-way ANOVA: Used when comparing the means of two or more groups while considering two independent categorical factors \n",
    "    (also known as factors or predictors). It allows for the examination of main effects of each factor and their interaction \n",
    "    effect.\n",
    "\n",
    "3. Repeated Measures ANOVA: Used when comparing the means of three or more related groups (e.g., within-subject designs) where\n",
    "    each participant is measured under different conditions. It accounts for the dependency among observations within the same \n",
    "    subject.\n",
    "Each type of ANOVA is suitable for different experimental designs and data structures, and the choice of ANOVA depends on the \n",
    "specific research question and the nature of the data being analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb52d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "Ans:\n",
    "    Partitioning of variance in ANOVA refers to the division of the total variance observed in the data into different compone-\n",
    "    nts to understand the sources of variability and their contributions to the overall variation in the dependent variable.\n",
    "\n",
    "In ANOVA, the total variance is decomposed into two main components:\n",
    "1. Between-group variance: This represents the variability among the group means and is attributed to the effect of the indepen-\n",
    "    dent variable (factor) being studied. It indicates how much the groups differ from each other.\n",
    "2. Within-group variance: This accounts for the variability within each group and reflects the random error or variability with-\n",
    "    in the groups.\n",
    "\n",
    "Understanding the partitioning of variance is essential because it helps researchers:\n",
    "\n",
    "1. Identify significant effects: By comparing the between-group variance to the within-group variance, ANOVA determines whether \n",
    "    the observed differences between groups are statistically significant.\n",
    "\n",
    "2. Quantify effect size: The ratio of between-group variance to within-group variance provides a measure of effect size, indicat\n",
    "    -ing the magnitude of the difference between groups.\n",
    "\n",
    "3. Interpret the results: Researchers can determine the proportion of variance attributed to the independent variable, which ai-\n",
    "    ds \n",
    "    in understanding the strength of the relationship between the factor and the dependent variable.\n",
    "\n",
    "4. Make informed decisions: By knowing the relative contributions of different sources of variance, researchers can make inform-\n",
    "    ed \n",
    "    decisions about experimental designs and the factors that influence the outcome.\n",
    "\n",
    "Overall, understanding the partitioning of variance in ANOVA enhances the accuracy and validity of statistical analyses and hel-\n",
    "ps draw meaningful conclusions from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "Ans:\n",
    "    In Python, you can calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares \n",
    "    (SSR) in a one-way ANOVA using the `scipy.stats` module. First, you need to import the necessary functions:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "```\n",
    "\n",
    "Next, you would have your data in the form of different groups or arrays. For example, if you have three groups, you might have:\n",
    "    \n",
    "\n",
    "```python\n",
    "group1 = [1, 2, 3, 4, 5]\n",
    "group2 = [3, 4, 5, 6, 7]\n",
    "group3 = [6, 7, 8, 9, 10]\n",
    "```\n",
    "\n",
    "Now, you can calculate SST, SSE, and SSR using the following steps:\n",
    "\n",
    "```python\n",
    "# Combine all the groups into one array\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "SST = np.sum((data - overall_mean)**2)\n",
    "\n",
    "# Calculate the group means\n",
    "group_means = [np.mean(group) for group in [group1, group2, group3]]\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "SSE = sum(len(group) * (mean - overall_mean)**2 for group, mean in zip([group1, group2, group3], group_means))\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "SSR = SST - SSE\n",
    "```\n",
    "\n",
    "Now, you have calculated SST, SSE, and SSR for the one-way ANOVA. These values can be used to assess the variance components and\n",
    "perform further statistical analysis. Note that in practice, you might use libraries like `statsmodels` or `scikit-learn` for\n",
    "more extensive ANOVA and post hoc tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "Ans:\n",
    "    In Python, you can calculate the main effects and interaction effects in a two-way ANOVA using the `statsmodels` library,\n",
    "    which provides an extensive set of statistical functions. Here's a step-by-step guide:\n",
    "\n",
    "1. Install the required libraries (if you haven't already):\n",
    "\n",
    "```python\n",
    "!pip install statsmodels\n",
    "```\n",
    "\n",
    "2. Import the necessary modules:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "```\n",
    "\n",
    "3. Prepare your data in a suitable format. You can create a DataFrame with the variables for the two factors and the dependent \n",
    "    variable. For example:\n",
    "\n",
    "```python\n",
    "data = {\n",
    "    'Factor1': [1, 1, 2, 2, 3, 3, 4, 4],\n",
    "    'Factor2': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'Dependent_Variable': [10, 12, 15, 14, 18, 20, 21, 22]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "4. Perform the two-way ANOVA and calculate the main effects and interaction effects:\n",
    "\n",
    "```python\n",
    "# Create the ANOVA model formula\n",
    "formula = 'Dependent_Variable ~ Factor1 + Factor2 + Factor1:Factor2'\n",
    "\n",
    "# Fit the model\n",
    "model = ols(formula, data=df).fit()\n",
    "\n",
    "# Perform the ANOVA\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract main effects and interaction effects from the ANOVA table\n",
    "main_effect_factor1 = anova_table.loc['Factor1', 'sum_sq']\n",
    "main_effect_factor2 = anova_table.loc['Factor2', 'sum_sq']\n",
    "interaction_effect = anova_table.loc['Factor1:Factor2', 'sum_sq']\n",
    "```\n",
    "\n",
    "Now, you have calculated the main effects for Factor1 and Factor2, as well as the interaction effect between them in the two-way\n",
    "                                   ANOVA using Python and the `statsmodels` library. The `sum_sq` column in the `anova_table`\n",
    "                                   DataFrame provides the sums of squares for each effect. These values can be used to assess \n",
    "                                   the significance and magnitude of the main and interaction effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8857b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test the null hypothesis that there are no significant differences between the\n",
    "means of the groups. The p-value associated with the F-statistic tells us the probability of obtaining the observed F-statistic\n",
    "(or a more extreme value) if the null hypothesis is true. \n",
    "\n",
    "In this case:\n",
    "- F-statistic: 5.23\n",
    "- p-value: 0.02\n",
    "\n",
    "Interpretation:\n",
    "Since the p-value (0.02) is less than the conventional significance level (e.g., 0.05), we reject the null hypothesis. This \n",
    "means that there are significant differences between the means of the groups being compared in the study.\n",
    "\n",
    "In other words, the results suggest that at least one of the groups has a different mean from the others. However, the ANOVA \n",
    "itself does not tell us which specific groups are different from each other. To identify which groups are significantly differ-\n",
    "ent, post hoc tests (e.g., Tukey's test, Bonferroni correction, etc.) can be performed to make pairwise comparisons between the \n",
    "                     groups and determine which group means differ significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?\n",
    "Ans:\n",
    "    Handling missing data in a repeated measures ANOVA can be crucial for obtaining accurate and reliable results. There are sev\n",
    "    eral methods to deal with missing data:\n",
    "\n",
    "1. Complete Case Analysis (Listwise Deletion): This method involves excluding any cases with missing data from the analysis. Wh-\n",
    "    ile it is straightforward, it can lead to a loss of statistical power and potential bias if the data is not missing comple-\n",
    "    -tely  at random (MCAR).\n",
    "\n",
    "2. Mean Imputation: Missing values are replaced with the mean value of the available data for that variable. This approach may \n",
    "    int-roduce bias, as it does not consider the relationship between the missing data and other variables.\n",
    "\n",
    "3. Last Observation Carried Forward (LOCF): Missing values are imputed using the last observed value. This method assumes that\n",
    "    the data is stable over time, which may not be true in many cases.\n",
    "\n",
    "4. Multiple Imputation: This method generates multiple plausible imputations for missing data, considering the relationships be-\n",
    "    tween variables. It provides more accurate estimates compared to simpler imputation methods.\n",
    "\n",
    "Potential consequences of using different methods to handle missing data:\n",
    "\n",
    "- Complete Case Analysis: This method can reduce the sample size and result in biased estimates if data is not MCAR. It may lead\n",
    "    to less reliable and less powerful statistical tests.\n",
    "\n",
    "- Mean Imputation: Mean imputation can lead to underestimation of standard errors and inflated statistical significance. It does\n",
    "    not account for uncertainty in the imputed values.\n",
    "\n",
    "- LOCF: This approach can lead to biased estimates, especially if the assumption of data stability is violated. It may not acc-\n",
    "    urately represent the underlying data patterns.\n",
    "\n",
    "- Multiple Imputation: Multiple imputation is considered one of the most robust methods for handling missing data. It takes into\n",
    "    account the uncertainty in the imputed values and provides valid statistical inferences.\n",
    "\n",
    "In summary, the choice of missing data handling method in repeated measures ANOVA can significantly impact the validity and rel-\n",
    "iability of the results. It is essential to carefully consider the missing data mechanism and choose an appropriate method to \n",
    "handle missing data to obtain accurate and meaningful conclusions. Multiple imputation is generally recommended when dealing \n",
    "with missing data, as it accounts for uncertainty and produces more reliable estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.\n",
    "Ans:\n",
    "    Common post-hoc tests used after ANOVA include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD) test: This test is used when you have conducted a one-way ANOVA and want to \n",
    "make all possible pairwise comparisons between the group means. It controls the familywise error rate (the probability of making\n",
    "                                    at least one Type I error) and is suitable for balanced designs.\n",
    "\n",
    "2. Bonferroni correction: This method adjusts the significance level for multiple comparisons by dividing the desired alpha \n",
    "    (e.g., 0.05) by the number of comparisons. It is suitable for controlling the familywise error rate in situations with many \n",
    "    comparisons.\n",
    "\n",
    "3. Scheffé test: This test is a more conservative alternative to Tukey's HSD and can be used for balanced or unbalanced designs.\n",
    "    It is more powerful when the number of groups is small and the sample sizes are unequal.\n",
    "\n",
    "4. Dunnett's test: This test is used to compare multiple treatment groups to a single control group. It is appropriate when you \n",
    "have a control group and want to assess if other treatment groups differ significantly from the control.\n",
    "\n",
    "Example situation:\n",
    "\n",
    "Suppose a researcher conducts a study to compare the effectiveness of four different treatments for reducing anxiety levels in \n",
    "atients. The study involves measuring anxiety levels in four treatment groups (A, B, C, D) and a control group (Placebo). The \n",
    "researcher performs a one-way ANOVA to test if there are significant differences between the groups. The ANOVA yields a statis-\n",
    "tically significant result, indicating that at least one group mean is different from the others.\n",
    "\n",
    "In this scenario, a post-hoc test like Tukey's HSD or Dunnett's test would be necessary. Tukey's HSD would be appropriate if the\n",
    "researcher wants to compare all possible pairs of treatment groups (A vs. B, A vs. C, A vs. D, B vs. C, B vs. D, C vs. D) to \n",
    "identify which groups have significantly different anxiety levels. On the other hand, if the researcher wants to compare the \n",
    "treatment groups (A, B, C, D) to the control group (Placebo), Dunnett's test would be more suitable to control the overall type\n",
    "I error rate for these specific comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.\n",
    "Ans:\n",
    "    To conduct a one-way ANOVA in Python and determine if there are significant differences between the mean weight loss of the\n",
    "    three diets (A, B, and C), you can use the `scipy.stats` module. Here's how you can do it:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Weight loss data for each diet (replace these with your actual data)\n",
    "diet_A = [3.5, 2.9, 4.1, 3.8, 2.7, ...]  # 50 weight loss values for diet A\n",
    "diet_B = [2.2, 1.8, 2.9, 2.5, 3.1, ...]  # 50 weight loss values for diet B\n",
    "diet_C = [1.1, 1.6, 0.9, 1.5, 1.2, ...]  # 50 weight loss values for diet C\n",
    "\n",
    "# Combine weight loss data from all diets into one array\n",
    "weight_loss_data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "# Create group labels (0 for diet A, 1 for diet B, 2 for diet C)\n",
    "group_labels = ['A'] * 50 + ['B'] * 50 + ['C'] * 50\n",
    "\n",
    "# Perform the one-way ANOVA\n",
    "F_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", F_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "```\n",
    "\n",
    "Interpretation:\n",
    "- F-statistic: The calculated F-statistic value from the ANOVA.\n",
    "- p-value: The p-value associated with the F-statistic.\n",
    "\n",
    "Suppose the output of the Python code is:\n",
    "```\n",
    "F-statistic: 9.27\n",
    "p-value: 1.78e-04\n",
    "```\n",
    "\n",
    "Interpretation of the results:\n",
    "The p-value (1.78e-04) is much smaller than the conventional significance level (e.g., 0.05), indicating strong evidence to rej-\n",
    "ect the null hypothesis. Therefore, we conclude that there are significant differences in the mean weight loss among the three\n",
    "diets (A, B, and C). Post hoc tests can be performed to determine which specific diets show statistically significant differen-\n",
    "ces in mean weight loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54bb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "Ans:\n",
    "    To conduct a two-way ANOVA in Python and determine if there are main effects or interaction effects between the software \n",
    "    programs and employee experience level, you can use the `statsmodels` library. Here's how you can do it:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate example data (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "n = 30\n",
    "software_programs = np.random.choice(['A', 'B', 'C'], size=n)\n",
    "employee_experience = np.random.choice(['novice', 'experienced'], size=n)\n",
    "completion_time = np.random.normal(loc=15, scale=2, size=n)\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = pd.DataFrame({'Software': software_programs, 'Experience': employee_experience, 'Time': completion_time})\n",
    "\n",
    "# Perform the two-way ANOVA\n",
    "model = ols('Time ~ Software + Experience + Software:Experience', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Print the ANOVA results\n",
    "print(anova_table)\n",
    "```\n",
    "\n",
    "Interpretation:\n",
    "The ANOVA results will provide the F-statistics and p-values for each main effect and the interaction effect.\n",
    "\n",
    "Suppose the output of the Python code is as follows:\n",
    "\n",
    "```\n",
    "                       df      sum_sq    mean_sq         F    PR(>F)\n",
    "Software              2.0   42.876200  21.438100  6.438656  0.003212\n",
    "Experience            1.0    0.234719   0.234719  0.070224  0.791221\n",
    "Software:Experience   2.0    3.877261   1.938631  0.581327  0.562568\n",
    "Residual             24.0  102.929712   4.288738       NaN       NaN\n",
    "```\n",
    "\n",
    "Interpretation of the results:\n",
    "- The p-value for the Software factor (PR(>F) = 0.003212) is less than the significance level (e.g., 0.05), indicating that the-\n",
    "re is a significant main effect of the software programs on completion time. In other words, the average completion time differs\n",
    "significantly among the three software programs.\n",
    "\n",
    "- The p-value for the Experience factor (PR(>F) = 0.791221) is greater than the significance level, indicating that there is no \n",
    "significant main effect of employee experience level on completion time. In other words, the average completion time does not\n",
    "differ significantly between novice and experienced employees.\n",
    "\n",
    "- The p-value for the Software:Experience interaction effect (PR(>F) = 0.562568) is greater than the significance level, indica-\n",
    "    ting that there is no significant interaction effect between the software programs and employee experience level on comple-\n",
    "    tion time. In other words, the effect of software programs on completion time does not differ significantly between novice \n",
    "    and experienced employees.\n",
    "\n",
    "Overall, the results suggest that the choice of software program has a significant impact on completion time, but employee expe-\n",
    "rience level does not significantly affect completion time, and there is no significant interaction effect between the two fac-\n",
    "tors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81056f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other.\n",
    "Ans:\n",
    "    To conduct a two-sample t-test in Python to determine if there are significant differences in test scores between the cont-\n",
    "    rol and experimental groups, you can use the `scipy.stats` module. If the results are significant, you can perform a post-\n",
    "    hoc test, such as Tukey's HSD, to identify which group(s) differ significantly from each other.\n",
    "\n",
    "Here's how you can do it:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate example data (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "control_group = np.random.normal(loc=75, scale=5, size=50)  # Test scores for the control group\n",
    "experimental_group = np.random.normal(loc=80, scale=5, size=50)  # Test scores for the experimental group\n",
    "\n",
    "# Perform the two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print the t-test results\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Perform a post-hoc test (e.g., Tukey's HSD) if the results are significant\n",
    "if p_value < 0.05:\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "    all_scores = np.concatenate([control_group, experimental_group])\n",
    "    group_labels = ['Control'] * len(control_group) + ['Experimental'] * len(experimental_group)\n",
    "\n",
    "    tukey_results = pairwise_tukeyhsd(all_scores, group_labels)\n",
    "    print(tukey_results)\n",
    "```\n",
    "\n",
    "Interpretation:\n",
    "- The t-statistic and p-value from the two-sample t-test will be printed. The p-value represents the probability of obtaining \n",
    "the observed difference in test scores (or a more extreme difference) if there were no true difference between the groups.\n",
    "\n",
    "- If the p-value is less than the significance level (e.g., 0.05), it indicates a significant difference in test scores between \n",
    "the control and experimental groups. You can then proceed with the post-hoc test to determine which group(s) differ significan-\n",
    "tly from each other.\n",
    "\n",
    "- The post-hoc test, in this case, is Tukey's HSD, which will provide information about which group(s) have significantly diffe-\n",
    "rent test scores.\n",
    "\n",
    "Please note that in practice, you should use your actual data instead of the generated example data and consider other factors\n",
    "such as assumptions of the t-test and post-hoc test to ensure the validity of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80784724",
   "metadata": {},
   "outputs": [],
   "source": [
    "To conduct a repeated measures ANOVA in Python to determine if there are significant differences in the average daily sales\n",
    "between three retail stores (Store A, Store B, and Store C), you can use the `statsmodels` library. If the results are signif-\n",
    "icant, you can perform a post-hoc test, such as Tukey's HSD, to identify which store(s) differ significantly from each other.\n",
    "\n",
    "Here's how you can do it:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# Generate example data (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "days = 30\n",
    "store_A_sales = np.random.normal(loc=500, scale=50, size=days)\n",
    "store_B_sales = np.random.normal(loc=480, scale=60, size=days)\n",
    "store_C_sales = np.random.normal(loc=520, scale=55, size=days)\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = pd.DataFrame({\n",
    "    'Day': list(range(1, days+1)) * 3,\n",
    "    'Store': ['A'] * days + ['B'] * days + ['C'] * days,\n",
    "    'Sales': np.concatenate([store_A_sales, store_B_sales, store_C_sales])\n",
    "})\n",
    "\n",
    "# Perform the repeated measures ANOVA\n",
    "rm_anova = AnovaRM(data, 'Sales', 'Day', within=['Store']).fit()\n",
    "\n",
    "# Print the ANOVA results\n",
    "print(rm_anova)\n",
    "\n",
    "# Perform a post-hoc test (e.g., Tukey's HSD) if the results are significant\n",
    "if rm_anova.anova_table['Pr > F']['Store'] < 0.05:\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "    tukey_results = pairwise_tukeyhsd(data['Sales'], data['Store'])\n",
    "    print(tukey_results)\n",
    "```\n",
    "\n",
    "Interpretation:\n",
    "- The results from the repeated measures ANOVA will be printed, including the F-statistic, p-value, and degrees of freedom for\n",
    "the 'Store' factor. The p-value represents the probability of obtaining the observed differences in sales (or more extreme diff-\n",
    "                            erences) if there were no true differences between the stores.\n",
    "\n",
    "- If the p-value for the 'Store' factor is less than the significance level (e.g., 0.05), it indicates a significant difference\n",
    "in average daily sales between the three stores. You can then proceed with the post-hoc test to determine which store(s) differ\n",
    "significantly from each other.\n",
    "\n",
    "- The post-hoc test, in this case, is Tukey's HSD, which will provide information about which store(s) have significantly diff-\n",
    "erent average daily sales.\n",
    "\n",
    "Please remember to use your actual data instead of the generated example data and consider other factors, such as the assumpti-\n",
    "ons of the repeated measures ANOVA and post-hoc test, to ensure the validity of the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
